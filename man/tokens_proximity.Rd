% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_dist.R
\name{tokens_proximity}
\alias{tokens_proximity}
\title{Extract Distance Information}
\usage{
tokens_proximity(
  x,
  keywords,
  get_min = TRUE,
  valuetype = c("glob", "regex", "fixed")
)
}
\arguments{
\item{x}{a \code{tokens} object}

\item{keywords}{a character vector of anchor words}

\item{get_min}{logical, whether to return only the minimum distance or raw distance information; it is more relevant when \code{keywords} have more than one word. See details.}

\item{valuetype}{See \link[quanteda:valuetype]{quanteda::valuetype}}
}
\value{
a \code{tokens_with_proximity} object. It is a derivative of \code{\link[quanteda:tokens]{quanteda::tokens()}}, i.e. all \verb{token_*} functions still work. A \code{tokens_with_proximity} has a modified \code{\link[=print]{print()}} method. Also, additional data slots are included
\itemize{
\item a document variation \code{dist}
\item a metadata slot \code{keywords}
\item a metadata slot \code{get_min}
}
}
\description{
This function extracts distance information from a \code{\link[quanteda:tokens]{quanteda::tokens()}} object.
}
\details{
The distance is measured by number of tokens away from the target. Given a tokenized sentence: \link{"I", "eat", "this", "apple"} and suppose "eat" is the target. The vector of minimum distances for each word from "eat" is \link{2, 1, 2, 3}. In another case: \link{"I", "wash", "and", "eat", "this", "apple"} and \link{"wash", "eat"} are the keywords. The minimal distance vector is \link{2, 1, 2, 1, 2, 3}. If \code{get_min} is \code{FALSE}, the output is a list of two vectors. For "wash", the distance vector is \link{1, 0, 1, 2, 3}. For "eat", \link{3, 2, 1, 0, 1, 2}. \code{get_min} always add 1 to the distance.
It is recommended to conduct all text maniputation tasks with all \verb{tokens_*()} functions before calling this function.
}
\examples{
library(quanteda)
ukimg_eu <- data_char_ukimmig2010 \%>\% tokens(remove_punct = TRUE) \%>\%
tokens_tolower() \%>\% tokens_proximity(c("eu", "euro*"))
ukimg_eu \%>\% dfm() \%>\% dfm_select(c("immig*", "migr*")) \%>\% rowSums() \%>\% sort()
## compare with
data_char_ukimmig2010 \%>\% tokens(remove_punct = TRUE) \%>\% tokens_tolower() \%>\%
dfm \%>\% dfm_select(c("immig*", "migr*")) \%>\% rowSums() \%>\% sort()
## rerun to select other keywords
ukimg_eu \%>\% tokens_proximity("britain")
}
\seealso{
\code{\link[=dfm.tokens_with_proximity]{dfm.tokens_with_proximity()}} \code{\link[quanteda:tokens]{quanteda::tokens()}}
}
